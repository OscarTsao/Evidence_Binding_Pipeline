# Current Production Pipeline
## Evidence Retrieval for Mental Health Research

**Last Updated:** 2026-01-18
**Status:** âœ… Production-Ready, Gold-Standard Validated
**Performance:** AUROC = 0.8972, Sensitivity = 99.78%

---

## Pipeline Overview

The current pipeline is a **6-stage evidence retrieval system** that takes a social media post and a DSM-5 criterion, then returns ranked evidence sentences with confidence scores.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INPUT                                       â”‚
â”‚  â€¢ Post text (Reddit submission)                                 â”‚
â”‚  â€¢ Criterion text (DSM-5 MDD criterion, e.g., "Depressed mood") â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: Dense Retrieval                                       â”‚
â”‚  Model: NV-Embed-v2 (nvidia/NV-Embed-v2)                        â”‚
â”‚  â€¢ Encode post sentences + criterion as dense vectors           â”‚
â”‚  â€¢ Compute cosine similarity                                     â”‚
â”‚  â€¢ Return top-24 candidates                                      â”‚
â”‚  Latency: ~100ms                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: Cross-Encoder Reranking                               â”‚
â”‚  Model: Jina-Reranker-v3 (jinaai/jina-reranker-v3)             â”‚
â”‚  â€¢ Rerank top-24 candidates with cross-encoder                  â”‚
â”‚  â€¢ More accurate relevance scoring                               â”‚
â”‚  â€¢ Return top-10 candidates                                      â”‚
â”‚  Latency: ~50ms                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: GNN Graph Reranker (P3) [OPTIONAL]                   â”‚
â”‚  Model: Heterogeneous GNN                                        â”‚
â”‚  â€¢ Build sentence-sentence graph (semantic similarity edges)    â”‚
â”‚  â€¢ Propagate relevance through graph                             â”‚
â”‚  â€¢ Refine ranking based on context                               â”‚
â”‚  Latency: ~30ms                                                  â”‚
â”‚  Contribution: +2-3% nDCG@10                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: Dynamic-K Selection (P2)                              â”‚
â”‚  Model: GNN-based adaptive selector                              â”‚
â”‚  â€¢ Analyze candidate quality and query difficulty               â”‚
â”‚  â€¢ Adaptively select K âˆˆ [0, 12] sentences to extract          â”‚
â”‚  â€¢ State-dependent policies:                                     â”‚
â”‚    - NEG: K = 0 (skip extraction)                               â”‚
â”‚    - UNCERTAIN: K âˆˆ [5, 12] (conservative)                      â”‚
â”‚    - POS: K âˆˆ [3, 12] (standard)                                â”‚
â”‚  Latency: ~5ms                                                   â”‚
â”‚  Mean K: 6.82 sentences/query                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5: No-Evidence Detection (P4 GNN NE Gate)                â”‚
â”‚  Model: Criterion-Aware Heterogeneous GNN                        â”‚
â”‚  â€¢ Binary classification: Has evidence vs No evidence           â”‚
â”‚  â€¢ Output: Probability P(has_evidence | post, criterion)        â”‚
â”‚  â€¢ Calibration: Isotonic regression (on TUNE split)             â”‚
â”‚  Latency: ~10ms                                                  â”‚
â”‚  Performance: AUROC = 0.8972, ECE = 0.0084 (well-calibrated)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 6: Three-State Clinical Gate                             â”‚
â”‚  Model: Threshold-based classifier                               â”‚
â”‚  â€¢ Input: Calibrated probability from P4                        â”‚
â”‚  â€¢ Thresholds (nested CV on TUNE split):                        â”‚
â”‚    - Ï„_neg = 0.0157 (NEG/UNCERTAIN boundary)                    â”‚
â”‚    - Ï„_pos = 0.8234 (UNCERTAIN/POS boundary)                    â”‚
â”‚  â€¢ Output states:                                                â”‚
â”‚    - NEG (p < Ï„_neg): Skip extraction (16.7% of queries)        â”‚
â”‚    - UNCERTAIN (Ï„_neg â‰¤ p < Ï„_pos): Manual review (14.9%)      â”‚
â”‚    - POS (p â‰¥ Ï„_pos): High confidence alert (68.3%)            â”‚
â”‚  Latency: <1ms                                                   â”‚
â”‚  Performance: 99.78% sensitivity, 93.5% alert precision         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT                                   â”‚
â”‚  â€¢ State: NEG / UNCERTAIN / POS                                 â”‚
â”‚  â€¢ Confidence: Calibrated probability [0, 1]                    â”‚
â”‚  â€¢ Evidence sentences: Top-K ranked sentences (K adaptive)      â”‚
â”‚  â€¢ Scores: Relevance scores per sentence                        â”‚
â”‚  â€¢ Metadata: Selected K, thresholds, model versions             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. NV-Embed-v2 Retriever (STAGE 1)

**What it does:** Dense embedding-based retrieval

**Model:** nvidia/NV-Embed-v2
- **Type:** Dense encoder (transformer-based)
- **Embedding dim:** 768
- **Max length:** 512 tokens
- **Selection:** Best of 25 retrievers tested (HPO)

**How it works:**
1. Split post into sentences (sentence corpus: 49,874 sentences from 1,477 posts)
2. Encode criterion text as dense vector
3. Encode all sentences from the post as dense vectors (cached)
4. Compute cosine similarity between criterion and each sentence
5. Return top-24 most similar sentences

**Performance:**
- Baseline nDCG@10: ~0.75-0.80
- Provides ~75-80% of final pipeline performance
- Latency: ~100ms per query

---

### 2. Jina-Reranker-v3 (STAGE 2)

**What it does:** Cross-encoder reranking for better relevance

**Model:** jinaai/jina-reranker-v3
- **Type:** Cross-encoder (BERT-based)
- **Selection:** Best of 15 rerankers tested (HPO)

**How it works:**
1. Take top-24 candidates from Stage 1
2. For each candidate, concatenate [criterion, sentence]
3. Pass through cross-encoder to get relevance score
4. Rerank by relevance scores
5. Return top-10 candidates

**Performance:**
- nDCG@10: 0.8658 (full pipeline with Stages 1+2)
- Marginal contribution: +7-9% over retrieval alone
- Latency: ~50ms per query

**Why cross-encoder?**
- More accurate than bi-encoder (considers token-level interactions)
- Trade-off: Slower but higher quality

---

### 3. P3 GNN Graph Reranker (STAGE 3) [OPTIONAL]

**What it does:** Graph-based refinement using sentence context

**Model:** Heterogeneous GNN
- **Node types:** Sentences, criterion
- **Edge types:** Sentence-sentence (semantic similarity), sentence-criterion (relevance)

**How it works:**
1. Build graph from top-10 candidates
2. Add edges between semantically similar sentences
3. Propagate relevance signals through graph
4. Update sentence scores based on context
5. Rerank by updated scores

**Performance:**
- Marginal contribution: +2-3% nDCG@10
- Latency: ~30ms per query

**Use case:** When context matters (e.g., related symptoms in nearby sentences)

---

### 4. P2 GNN Dynamic-K Selection (STAGE 4)

**What it does:** Adaptively decides how many sentences to extract

**Model:** GNN-based regressor
- **Input:** Candidate quality, query difficulty, state
- **Output:** K âˆˆ [0, 12]

**Policies by state:**
```python
NEG_POLICY = {
    'k_min': 0,
    'k_max': 0,
    'k_ratio': 0.0
}

UNCERTAIN_POLICY = {
    'k_min': 5,
    'k_max': 12,
    'k_ratio': 0.7,
    'gamma': 0.95
}

POS_POLICY = {
    'k_min': 3,
    'k_max': 12,
    'k_ratio': 0.6,
    'gamma': 0.9
}
```

**How it works:**
1. Analyze candidate scores and distribution
2. Estimate query difficulty
3. Select K based on state and policy
4. Extract top-K sentences

**Performance:**
- Mean K: 6.82 sentences/query
- Median K: 6.0
- Adaptive to candidate quality (correlation = 0.998)
- Marginal contribution: +1-2% precision

---

### 5. P4 GNN NE Gate (STAGE 5)

**What it does:** Detects if post has evidence for criterion (binary classification)

**Model:** Criterion-Aware Heterogeneous GNN
- **Architecture:** 2-layer GNN with criterion embeddings
- **Training:** Supervised on 14,770 labeled queries
- **Calibration:** Isotonic regression on TUNE split

**Graph structure:**
```
Nodes:
- Post node (1)
- Criterion node (1)
- Sentence nodes (N)

Edges:
- Post â†’ Sentences (contains)
- Criterion â†’ Sentences (relevance, from Jina scores)
- Sentence â†” Sentence (semantic similarity)
```

**How it works:**
1. Build heterogeneous graph for the query
2. Initialize node features (embeddings from NV-Embed-v2)
3. Message passing through GNN (2 layers)
4. Readout on criterion node
5. Output probability P(has_evidence)
6. Calibrate with isotonic regression

**Performance:**
- **AUROC:** 0.8972 â­ (excellent discrimination)
- **AUPRC:** 0.5709
- **Calibration (ECE):** 0.0084 (very well-calibrated)
- **Brier Score:** 0.0554 (low prediction error)
- Latency: ~10ms per query

**Why it matters:** Core component for clinical deployment

---

### 6. Three-State Clinical Gate (STAGE 6)

**What it does:** Maps probabilities to clinical decisions

**Thresholds (learned on TUNE split):**
- **Ï„_neg = 0.0157:** Below this = NEG (skip extraction)
- **Ï„_pos = 0.8234:** Above this = POS (high confidence alert)

**States:**

**NEG (p < 0.0157):**
- **Interpretation:** Very likely no evidence
- **Action:** Skip evidence extraction entirely
- **Workload:** 0 sentences extracted (K=0)
- **Frequency:** 16.7% of queries
- **Benefit:** ~17% computational savings

**UNCERTAIN (0.0157 â‰¤ p < 0.8234):**
- **Interpretation:** Ambiguous, needs review
- **Action:** Extract conservatively (K âˆˆ [5,12])
- **Workload:** Mean K = 6.5 sentences
- **Frequency:** 14.9% of queries
- **Recommendation:** Manual clinical review

**POS (p â‰¥ 0.8234):**
- **Interpretation:** High confidence evidence present
- **Action:** Standard extraction (K âˆˆ [3,12])
- **Workload:** Mean K = 6.2 sentences
- **Frequency:** 68.3% of queries
- **Alert precision:** 93.5% (very reliable)

**Performance:**
- **Screening Sensitivity:** 99.78% (only 2.2 FN per 1,000 queries)
- **Screening FN/1000:** 2.2 (target: â‰¤5) âœ…
- **Alert Precision:** 93.5% (target: â‰¥90%) âœ…

**Threshold Selection Method:**
- Nested cross-validation on TUNE split (20% of each fold)
- Optimize for: sensitivity â‰¥99%, alert precision â‰¥90%
- Re-selected per fold to prevent overfitting

---

## Optional: LLM Augmentation Modules

**These are implemented but NOT in the main pipeline by default.**

### M1: LLM Listwise Reranker

**Status:** âœ… Implemented, production-ready
**File:** `src/final_sc_review/llm/reranker.py`

**What it does:** Re-rank top-10 candidates using Qwen2.5-7B-Instruct

**Model:** Qwen/Qwen2.5-7B-Instruct
- 4-bit quantization
- Temperature: 0.0 (deterministic)
- Response caching (SHA-256 hashed prompts)

**Performance vs Jina-v3:**
- nDCG@10: ~0.84-0.86 (competitive)
- Latency: ~2-5s (vs 50ms for Jina-v3)

**Use case:** Batch processing, high-precision mode

---

### M2: LLM Evidence Verifier

**Status:** âœ… Implemented, production-ready
**File:** `src/final_sc_review/llm/verifier.py`

**What it does:** Binary verification with self-consistency

**How it works:**
1. Take top-K from pipeline
2. Run LLM verification (N=3 times, temperature=0.7)
3. Majority vote for binary decision
4. Confidence = consistency fraction

**Performance:**
- Binary accuracy: ~85-88%
- As post-filter: +3-5% precision, -2-3% recall

**Use case:** False positive reduction for high-stakes queries

---

## End-to-End Performance

### Full Pipeline (Stages 1-6)

**On 14,770 queries (1,477 posts Ã— 10 criteria):**

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **AUROC** | 0.8972 | Excellent evidence detection |
| **AUPRC** | 0.5709 | Good precision-recall tradeoff |
| **Screening Sensitivity** | 99.78% | Only 2.2 FN per 1,000 |
| **Alert Precision** | 93.5% | 93.5% of POS alerts correct |
| **Evidence Recall@10** | 70.4% | 70% of evidence retrieved |
| **Evidence Precision@10** | 22.6% | 23% of top-10 are evidence |
| **nDCG@10** | 0.8658 | Excellent ranking quality |
| **MRR** | 0.3801 | First evidence at rank ~2.6 |
| **Mean K** | 6.82 | Avg 7 sentences extracted |

### Latency Breakdown

**Per query (single GPU: RTX 5090):**
```
Stage 1 (NV-Embed-v2):      100ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Stage 2 (Jina-v3):           50ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Stage 3 (P3 GNN):            30ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [optional]
Stage 4 (P2 Dynamic-K):       5ms  â–ˆ
Stage 5 (P4 NE Gate):        10ms  â–ˆâ–ˆ
Stage 6 (Three-State):       <1ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                      ~195ms
```

**Throughput:**
- Single GPU: ~5-10 QPS
- Dual GPU (load balanced): ~15-20 QPS
- Batch processing (32 queries): ~50-80 QPS

---

## Data Flow Example

**Input:**
```json
{
  "post_id": "abc123",
  "post_text": "I've been feeling really down for the past 3 weeks. Can't sleep, no energy, don't enjoy anything anymore. Just want to stay in bed all day.",
  "criterion_id": "A.1",
  "criterion_text": "Depressed mood most of the day, nearly every day"
}
```

**Processing:**

**Stage 1 (Retrieval):** Top-24 candidates
```
1. "I've been feeling really down for the past 3 weeks." (score: 0.89)
2. "Can't sleep, no energy, don't enjoy anything anymore." (score: 0.76)
3. "Just want to stay in bed all day." (score: 0.71)
...
24. "The weather has been nice lately." (score: 0.12)
```

**Stage 2 (Reranking):** Top-10 refined
```
1. "I've been feeling really down for the past 3 weeks." (score: 0.95) â­
2. "Can't sleep, no energy, don't enjoy anything anymore." (score: 0.82)
3. "Just want to stay in bed all day." (score: 0.78)
...
10. "I went to the store yesterday." (score: 0.23)
```

**Stage 3 (Graph Reranking):** Contextual refinement
```
1. "I've been feeling really down for the past 3 weeks." (score: 0.97) â­
2. "Can't sleep, no energy, don't enjoy anything anymore." (score: 0.85)
3. "Just want to stay in bed all day." (score: 0.80)
...
```

**Stage 4 (Dynamic-K):** Select K=3 (POS state, high confidence)

**Stage 5 (P4 NE Gate):** P(has_evidence) = 0.92 (high confidence)

**Stage 6 (Three-State):**
- 0.92 > Ï„_pos (0.8234) â†’ **POS state**

**Output:**
```json
{
  "state": "POS",
  "confidence": 0.92,
  "selected_k": 3,
  "evidence_sentences": [
    {
      "text": "I've been feeling really down for the past 3 weeks.",
      "score": 0.97,
      "rank": 1
    },
    {
      "text": "Can't sleep, no energy, don't enjoy anything anymore.",
      "score": 0.85,
      "rank": 2
    },
    {
      "text": "Just want to stay in bed all day.",
      "score": 0.80,
      "rank": 3
    }
  ],
  "thresholds": {
    "tau_neg": 0.0157,
    "tau_pos": 0.8234
  },
  "metadata": {
    "retriever": "nv-embed-v2",
    "reranker": "jina-reranker-v3",
    "p4_version": "hetero_gnn_v1",
    "git_commit": "808c4c4"
  }
}
```

---

## Configuration

**Current production config:** `configs/default.yaml`

```yaml
models:
  retriever_name: "nv-embed-v2"      # Best of 25 retrievers
  reranker_name: "jina-reranker-v3"  # Best of 15 rerankers

retriever:
  top_k_retriever: 24                # Stage 1 output
  top_k_final: 10                    # Stage 2 output
  use_sparse: false                  # Dense only (no BM25)
  use_colbert: false                 # Dense only (no ColBERT)
  fusion_method: "rrf"               # Reciprocal Rank Fusion
  rrf_k: 60

gnn:
  use_p3_graph: true                 # Enable P3 graph reranker
  use_p2_dynamic_k: true             # Enable P2 dynamic-K
  use_p4_ne_gate: true               # Enable P4 NE gate

clinical:
  use_three_state_gate: true         # Enable NEG/UNCERTAIN/POS
  sensitivity_target: 0.99           # 99% sensitivity target
  min_alert_precision: 0.90          # 90% alert precision target

  neg_policy:
    k_min: 0
    k_max: 0

  uncertain_policy:
    k_min: 5
    k_max: 12
    k_ratio: 0.7
    gamma: 0.95

  pos_policy:
    k_min: 3
    k_max: 12
    k_ratio: 0.6
    gamma: 0.9

device: "cuda"                       # GPU inference
random_seed: 42                      # Reproducibility
```

---

## Component Status

| Component | Status | Performance | Notes |
|-----------|--------|-------------|-------|
| **NV-Embed-v2** | âœ… Production | nDCG ~0.75-0.80 | Best of 25 retrievers |
| **Jina-v3** | âœ… Production | nDCG 0.8658 | Best of 15 rerankers |
| **P3 Graph** | âœ… Production | +2-3% nDCG | Optional, can be disabled |
| **P2 Dynamic-K** | âœ… Production | +1-2% precision | Adaptive K selection |
| **P4 NE Gate** | âœ… Production | AUROC 0.8972 | Core component |
| **Three-State** | âœ… Production | 99.78% sensitivity | Clinical deployment |
| **M1 LLM Reranker** | âœ… Available | nDCG ~0.84-0.86 | Optional (slow) |
| **M2 LLM Verifier** | âœ… Available | +3-5% precision | Optional post-filter |

---

## Validation Status

**Gold-Standard Compliance:** 10/10 âœ…

1. âœ… No data leakage (Post-ID disjoint splits)
2. âœ… Nested threshold selection (TUNE split only)
3. âœ… No gold features (text-only)
4. âœ… Independent metric verification (exact match)
5. âœ… Reproducibility (git + seeds + config)
6. âœ… Stratified splits (balanced)
7. âœ… Comprehensive metrics (25+)
8. âœ… Statistical significance (5-fold CV, 95% CI)
9. âœ… Failure mode analysis (per-criterion)
10. âœ… Complete documentation (3,500+ lines)

**Tests:** 40/40 passing âœ…
- Unit tests: 28/28
- Leakage tests: 12/12

---

## Usage

### Command-Line

```bash
# Single query inference
python scripts/run_single.py \
  --post_id abc123 \
  --criterion_id A.1 \
  --config configs/default.yaml

# Batch evaluation
python scripts/eval_sc_pipeline.py \
  --config configs/default.yaml \
  --split test

# 5-fold cross-validation
python scripts/run_clinical_high_recall_eval.py \
  --n_folds 5 \
  --output_dir outputs/clinical_eval
```

### Python API

```python
from final_sc_review.pipeline.zoo_pipeline import ZooPipeline, ZooPipelineConfig
from final_sc_review.data.io import load_sentence_corpus

# Load data
sentences = load_sentence_corpus("data/sentence_corpus.jsonl")

# Configure pipeline
config = ZooPipelineConfig(
    retriever_name="nv-embed-v2",
    reranker_name="jina-reranker-v3",
    top_k_retriever=24,
    top_k_final=10,
    device="cuda"
)

# Initialize pipeline
pipeline = ZooPipeline(
    sentences=sentences,
    cache_dir="data/cache",
    config=config
)

# Run inference
results = pipeline.retrieve(
    query="Depressed mood most of the day, nearly every day",
    post_id="abc123",
    top_k=10
)

# Results: List[(sent_uid, sentence_text, score)]
for uid, text, score in results:
    print(f"{score:.3f} | {text}")
```

---

## Summary

**Current Pipeline = 6-Stage Evidence Retrieval System**

1. âœ… **NV-Embed-v2** (dense retrieval, top-24)
2. âœ… **Jina-Reranker-v3** (cross-encoder, top-10)
3. âœ… **P3 GNN** (graph refinement, optional)
4. âœ… **P2 Dynamic-K** (adaptive K selection)
5. âœ… **P4 NE Gate** (evidence detection, AUROC=0.8972)
6. âœ… **Three-State Gate** (NEG/UNCERTAIN/POS, 99.78% sensitivity)

**Plus Optional:**
- ğŸ”§ **M1 LLM Reranker** (available, slower)
- ğŸ”§ **M2 LLM Verifier** (available, post-filter)

**Performance:**
- AUROC: 0.8972
- Sensitivity: 99.78%
- Alert Precision: 93.5%
- Latency: ~195ms per query

**Status:** âœ… **Production-Ready, Gold-Standard Validated**

---

**Last Updated:** 2026-01-18
**Git Commit:** 808c4c4
**Validation:** 10/10 gold-standard requirements met
