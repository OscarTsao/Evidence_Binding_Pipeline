# DEFAULT CONFIGURATION - BEST MODEL COMBO
# Updated: 2026-02-03 based on comprehensive ablation (17+ configs tested)
# Best combo: nv-embed-v2 + jina-reranker-v3 + SAGE+Residual GNN
# Performance (5-fold CV):
#   - Baseline: nDCG@10 = 0.7330 ± 0.031
#   - With P3 GNN (SAGE+Residual): nDCG@10 = 0.8206 ± 0.030 (+10.48%)
#
# A.10 Exclusion: A.10 (SPECIAL_CASE) is excluded from GNN training by default.
# See: outputs/comprehensive_ablation/ for full experiment results.
#
# Note: This config supports the Zoo pipeline with NV-Embed-v2 + Jina-Reranker-v3

paths:
  data_dir: data
  groundtruth: data/groundtruth/evidence_sentence_groundtruth.csv
  sentence_corpus: data/groundtruth/sentence_corpus.jsonl
  cache_dir: data/cache

models:
  # === Zoo Pipeline (BEST) - Use with scripts/eval_zoo_pipeline.py ===
  # Best retriever from HPO model zoo (324 combinations tested)
  retriever_name: nv-embed-v2
  retriever_model_id: nvidia/NV-Embed-v2

  # Best reranker from HPO model zoo
  reranker_name: jina-reranker-v3
  reranker_model_id: jinaai/jina-reranker-v3

  # === Legacy Pipeline - For backward compatibility ===
  # These are used by scripts/eval_sc_pipeline.py and scripts/run_single.py
  bge_m3: BAAI/bge-m3
  jina_v3: jinaai/jina-reranker-v3
  bge_query_max_length: 128
  bge_passage_max_length: 256
  bge_use_fp16: true
  bge_batch_size: 64
  reranker_max_length: 1024
  reranker_chunk_size: 128
  reranker_dtype: auto
  reranker_use_listwise: true

retriever:
  # Best HPO parameters (from 50 trials on nv-embed-v2 + jina-reranker-v3)
  top_k_retriever: 24
  top_k_rerank: 24
  top_k_final: 10
  use_sparse: false  # nv-embed-v2 is dense-only
  use_colbert: false  # nv-embed-v2 is dense-only
  use_multiv: false
  dense_weight: 1.0
  sparse_weight: 0.0
  colbert_weight: 0.0
  fusion_method: rrf
  score_normalization: none
  rrf_k: 60
  rebuild_cache: false

split:
  seed: 42
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1

# Training configuration
training:
  # A.10 is excluded by default (not a DSM-5 criterion, hurts A.1-A.9 performance)
  exclude_criteria: ["A.10"]
  dsm5_criteria: ["A.1", "A.2", "A.3", "A.4", "A.5", "A.6", "A.7", "A.8", "A.9"]

evaluation:
  split: test
  ks: [1, 3, 5, 10, 20]
  skip_no_positives: true
  save_query_csv: true

# GNN Configuration (P3 Graph Reranker)
# SAGE + Residual - verified best from comprehensive ablation
gnn:
  # Architecture options: gcn, sage, gat, gatv2
  architecture: sage  # Use enum value matching GNNType
  hidden_dim: 128
  num_heads: 2
  num_layers: 2  # 2 layers + residual = best
  dropout: 0.05
  activation: gelu
  alpha_init: 0.65
  learn_alpha: true
  use_residual: true
  use_layer_norm: false  # LayerNorm hurts performance (-2.38%)
  # Training
  lr: 3.69e-05
  weight_decay: 9.06e-06
  max_epochs: 25
  batch_size: 32
  patience: 10
  margin: 0.1  # For PairwiseMarginLoss

# Metadata
metadata:
  updated: "2026-02-03"
  hpo_combo: "nv-embed-v2 + jina-reranker-v3 + SAGE+Residual"
  baseline_ndcg10: 0.7330
  gnn_ndcg10: 0.8206
  gnn_improvement: "+10.48%"
  gnn_architecture: "SAGE + Residual + GELU"
  cv_folds: 5
  a10_exclusion: true
  notes: |
    Best configuration validated with 5-fold cross-validation.
    SAGE+Residual achieves 0.8206 nDCG@10 (+10.48% over baseline).
    Source of truth: outputs/comprehensive_ablation/

    Available GNN types: gcn, sage, gat, gatv2

    Conda environments:
      - nv-embed-v2: For NV-Embed-v2 retriever encoding
      - llmhe: For all other operations (reranking, GNN, evaluation)

    For GNN training (excludes A.10 by default):
      conda run -n llmhe python scripts/gnn/train_p3_graph_reranker.py --gnn_type sage
